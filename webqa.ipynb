{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/ricky42613/miniconda3/envs/topic_gen/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ricky42613/miniconda3/envs/topic_gen/lib/python3.9/site-packages (from beautifulsoup4) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricky42613/miniconda3/envs/topic_gen/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarkupLMProcessor, MarkupLMForQuestionAnswering\n",
    "\n",
    "processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")\n",
    "model = MarkupLMForQuestionAnswering.from_pretrained(\"microsoft/markuplm-base-finetuned-websrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = \"\"\"<html> <head> <title>My name is Niels</title> </head> </html>\"\"\"\n",
    "question = \"what is his name?\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = processor(html_string, questions=question, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Niels'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# we use torch.no_grad() as we don't need any gradient computation here\n",
    "# we're just doing inference! This saves memory\n",
    "with torch.no_grad():\n",
    "  outputs = model(**encoding)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = encoding.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "ans = processor.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-2.5185, -7.5897, -7.5423, -8.0176, -7.7516, -7.7941, -1.5377, -3.2046,\n",
       "         -5.7682, -4.1791,  0.6520, -2.7696, -1.5378]]), end_logits=tensor([[-3.8667, -9.1639, -8.3935, -8.5618, -8.1168, -8.2841, -0.9340, -7.2121,\n",
       "         -6.9536, -5.7640, -3.8340,  2.8132, -0.9340]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
